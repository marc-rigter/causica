seed_everything: 123
wandb_group: avid_adapter
wandb_name: avid_adapter

data:
  class_path: dwma.lightning.data_modules.procgen_data.ProcgenDataModule
  init_args:
    batch_size: 32
    window_width: 12
    train_data_folder: /datasets/coinrun_500lvl_train
    test_data_folder: /datasets/coinrun_test
    val_data_folder: /datasets/coinrun_test
    cache_files: False
    precache_files: False
    num_workers: 4
    fixed_episode_length: 50

trainer:
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      save_dir: /host_home/wandb/
      offline: False
      project: avid
      entity: causica
      log_model: all
  devices: [0]
  accelerator: "gpu"
  accumulate_grad_batches: 2
  gradient_clip_val: 1.0
  max_epochs: 5000
  limit_train_batches: 2000
  limit_val_batches: 200
  log_every_n_steps: 10
  precision: 16
  callbacks:
    class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      dirpath: "/host_home/avid_checkpoints"
      filename: "{epoch}-{step}"
      save_weights_only: True
      save_last: False
      every_n_epochs: 5 # Change this to the desired frequency
      save_top_k: -1 # save all checkpoints
